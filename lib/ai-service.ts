import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import { AIProvider, AIConfig } from '@/types';

export class AIService {
  private openai: OpenAI | null = null;
  private anthropic: Anthropic | null = null;

  constructor() {
    // åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    if (process.env.OPENAI_API_KEY) {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
    }

    // åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯
    if (process.env.ANTHROPIC_API_KEY) {
      this.anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY,
      });
    }
  }

  // åˆ›å»ºåŠ¨æ€çš„OpenAIå®¢æˆ·ç«¯
  private createOpenAIClient(config: AIConfig): OpenAI {
    return new OpenAI({
      apiKey: config.apiKey || process.env.OPENAI_API_KEY,
      baseURL: config.baseURL,
    });
  }

  async generateResponse(prompt: string, config: AIConfig = {
    provider: 'openai',
    model: 'gpt-4',
    temperature: 0.7,
    maxTokens: 2000
  }): Promise<string> {
    const startTime = Date.now();

    try {
      if (config.provider === 'openai' || config.provider === 'deepseek' || config.provider === 'custom') {
        // ä½¿ç”¨åŠ¨æ€å®¢æˆ·ç«¯æˆ–é»˜è®¤å®¢æˆ·ç«¯
        const client = config.apiKey || config.baseURL ? this.createOpenAIClient(config) : this.openai;
        
        if (!client) {
          throw new Error('OpenAI API æœªé…ç½®');
        }

        const response = await client.chat.completions.create({
          model: config.model,
          messages: [{ role: 'user', content: prompt }],
          temperature: config.temperature,
          max_tokens: config.maxTokens,
          top_p: config.topP,
        });

        const executionTime = Date.now() - startTime;
        console.log(`API call completed in ${executionTime}ms`);
        
        return response.choices[0]?.message?.content || 'æ— æ³•ç”Ÿæˆå“åº”';
      }

      if (config.provider === 'anthropic' && this.anthropic) {
        const response = await this.anthropic.messages.create({
          model: config.model || 'claude-3-sonnet-20240229',
          max_tokens: config.maxTokens || 2000,
          temperature: config.temperature,
          messages: [{ role: 'user', content: prompt }],
        });

        const executionTime = Date.now() - startTime;
        console.log(`Anthropic API call completed in ${executionTime}ms`);
        
        return response.content[0]?.type === 'text' 
          ? response.content[0].text 
          : 'æ— æ³•ç”Ÿæˆå“åº”';
      }

      throw new Error('æœªé…ç½®å¯ç”¨çš„AIæœåŠ¡æä¾›å•†');
    } catch (error) {
      console.error('AI APIè°ƒç”¨å¤±è´¥:', error);
      throw new Error('AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•');
    }
  }

  // æµå¼ç”Ÿæˆå“åº”
  async generateStreamResponse(
    prompt: string, 
    config: AIConfig,
    onChunk: (chunk: string) => void
  ): Promise<string> {
    const startTime = Date.now();
    let fullResponse = '';

    try {
      if (config.provider === 'openai' || config.provider === 'deepseek' || config.provider === 'custom') {
        const client = config.apiKey || config.baseURL ? this.createOpenAIClient(config) : this.openai;
        
        if (!client) {
          throw new Error('OpenAI API æœªé…ç½®');
        }

        const stream = await client.chat.completions.create({
          model: config.model,
          messages: [{ role: 'user', content: prompt }],
          temperature: config.temperature,
          max_tokens: config.maxTokens,
          top_p: config.topP,
          stream: true,
        });

        for await (const chunk of stream) {
          const content = chunk.choices[0]?.delta?.content || '';
          if (content) {
            fullResponse += content;
            onChunk(content);
          }
        }

        const executionTime = Date.now() - startTime;
        console.log(`Stream API call completed in ${executionTime}ms`);
        
        return fullResponse;
      }

      if (config.provider === 'anthropic' && this.anthropic) {
        // Anthropic æš‚æ—¶ä½¿ç”¨éæµå¼ï¼Œå› ä¸ºSDKå¤æ‚æ€§
        const response = await this.anthropic.messages.create({
          model: config.model || 'claude-3-sonnet-20240229',
          max_tokens: config.maxTokens || 2000,
          temperature: config.temperature,
          messages: [{ role: 'user', content: prompt }],
        });

        const content = response.content[0]?.type === 'text' 
          ? response.content[0].text 
          : 'æ— æ³•ç”Ÿæˆå“åº”';
        
        // æ¨¡æ‹Ÿæµå¼è¾“å‡º
        const words = content.split(' ');
        for (let i = 0; i < words.length; i++) {
          const chunk = (i === 0 ? '' : ' ') + words[i];
          fullResponse += chunk;
          onChunk(chunk);
          await new Promise(resolve => setTimeout(resolve, 50)); // 50mså»¶è¿Ÿ
        }

        return fullResponse;
      }

      throw new Error('æœªé…ç½®å¯ç”¨çš„AIæœåŠ¡æä¾›å•†');
    } catch (error) {
      console.error('AI APIè°ƒç”¨å¤±è´¥:', error);
      throw new Error('AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•');
    }
  }

  // ç”Ÿæˆå…ƒPrompt
  async generateMetaPrompt(scenario: string, domain: string, config?: AIConfig): Promise<string> {
    const metaPromptTemplate = `ä½œä¸ºPromptå·¥ç¨‹ä¸“å®¶ï¼Œè¯·ä¸º"${scenario}"åœºæ™¯åœ¨"${domain}"é¢†åŸŸè®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„Promptæ¨¡æ¿ã€‚

è¦æ±‚ï¼š
1. æ˜ç¡®è§’è‰²å®šä½å’Œä¸“ä¸šèº«ä»½
2. ç»“æ„åŒ–è¾“å…¥æ ¼å¼
3. å…·ä½“è¾“å‡ºè¦æ±‚
4. è´¨é‡æ£€éªŒæ ‡å‡†
5. åŒ…å«å®é™…åº”ç”¨ç¤ºä¾‹

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

**åœºæ™¯**: ${scenario}
**é¢†åŸŸ**: ${domain}

**ä¸“ç”¨Promptæ¨¡æ¿:**
[è¯¦ç»†çš„Promptæ¨¡æ¿å†…å®¹]

**ä½¿ç”¨è¯´æ˜:**
[å¦‚ä½•ä½¿ç”¨æ­¤æ¨¡æ¿çš„å…·ä½“æŒ‡å¯¼]

**é¢„æœŸæ•ˆæœ:**
[ä½¿ç”¨æ­¤æ¨¡æ¿èƒ½è¾¾åˆ°çš„æ•ˆæœå’Œä»·å€¼]`;

    return await this.generateResponse(metaPromptTemplate, config || {
      provider: 'openai',
      model: 'gpt-4',
      temperature: 0.3, // è¾ƒä½æ¸©åº¦ç¡®ä¿ç»“æ„åŒ–è¾“å‡º
    });
  }

  // ç”ŸæˆPRD
  async generatePRD(requirements: string, context?: string): Promise<string> {
    const prdPrompt = `ä½œä¸ºèµ„æ·±äº§å“ç»ç†ï¼ŒåŸºäºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„äº§å“éœ€æ±‚æ–‡æ¡£(PRD)ï¼š

**åŸå§‹éœ€æ±‚:**
${requirements}

**èƒŒæ™¯ä¿¡æ¯:**
${context || 'æš‚æ— é¢å¤–èƒŒæ™¯ä¿¡æ¯'}

**è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”ŸæˆPRD:**

# äº§å“éœ€æ±‚æ–‡æ¡£ (PRD)

## 1. äº§å“æ¦‚è¿°
- äº§å“åç§°
- äº§å“å®šä½
- ç›®æ ‡ç”¨æˆ·ç¾¤ä½“

## 2. éœ€æ±‚èƒŒæ™¯
- é—®é¢˜æè¿°
- å¸‚åœºæœºä¼š
- å•†ä¸šä»·å€¼

## 3. äº§å“ç›®æ ‡
- æ ¸å¿ƒç›®æ ‡
- æˆåŠŸæŒ‡æ ‡
- é¢„æœŸæ”¶ç›Š

## 4. åŠŸèƒ½éœ€æ±‚
### 4.1 æ ¸å¿ƒåŠŸèƒ½
- åŠŸèƒ½åˆ—è¡¨
- åŠŸèƒ½æè¿°
- ä¼˜å…ˆçº§æ’åº

### 4.2 åŠŸèƒ½è§„æ ¼
- è¯¦ç»†åŠŸèƒ½è¯´æ˜
- äº¤äº’æµç¨‹
- ä¸šåŠ¡è§„åˆ™

## 5. éåŠŸèƒ½éœ€æ±‚
- æ€§èƒ½è¦æ±‚
- å®‰å…¨è¦æ±‚
- å¯ç”¨æ€§è¦æ±‚

## 6. æŠ€æœ¯è¦æ±‚
- æŠ€æœ¯é€‰å‹å»ºè®®
- æ¶æ„çº¦æŸ
- é›†æˆè¦æ±‚

## 7. ç”¨æˆ·ä½“éªŒè®¾è®¡
- ç•Œé¢è¦æ±‚
- äº¤äº’è®¾è®¡
- å“åº”å¼è®¾è®¡

## 8. é¡¹ç›®è§„åˆ’
- å¼€å‘é˜¶æ®µ
- æ—¶é—´è®¡åˆ’
- èµ„æºéœ€æ±‚

## 9. é£é™©è¯„ä¼°
- æŠ€æœ¯é£é™©
- å¸‚åœºé£é™©
- èµ„æºé£é™©

## 10. éªŒæ”¶æ ‡å‡†
- åŠŸèƒ½éªŒæ”¶
- æ€§èƒ½éªŒæ”¶
- ç”¨æˆ·éªŒæ”¶

è¯·ç¡®ä¿å†…å®¹è¯¦ç»†ã€ä¸“ä¸šä¸”å¯æ‰§è¡Œã€‚`;

    return await this.generateResponse(prdPrompt, {
      provider: 'openai',
      model: 'gpt-4',
      temperature: 0.2,
      maxTokens: 4000,
    });
  }

  // ä»£ç å®¡æŸ¥
  async reviewCode(code: string, language: string = 'javascript'): Promise<string> {
    const reviewPrompt = `ä½œä¸ºèµ„æ·±${language}ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹ä»£ç è¿›è¡Œå…¨é¢å®¡æŸ¥ï¼š

**ä»£ç å†…å®¹:**
\`\`\`${language}
${code}
\`\`\`

**è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œå®¡æŸ¥:**

## ğŸ” ä»£ç è´¨é‡åˆ†æ
- å¯è¯»æ€§å’Œä»£ç é£æ ¼
- å‘½åè§„èŒƒ
- ä»£ç ç»“æ„å’Œç»„ç»‡

## âš¡ æ€§èƒ½è¯„ä¼°
- æ—¶é—´å¤æ‚åº¦åˆ†æ
- ç©ºé—´å¤æ‚åº¦åˆ†æ
- æ½œåœ¨æ€§èƒ½ç“¶é¢ˆ

## ğŸ”’ å®‰å…¨éšæ‚£
- è¾“å…¥éªŒè¯é—®é¢˜
- æ½œåœ¨å®‰å…¨æ¼æ´
- æ•°æ®å®‰å…¨é£é™©

## ğŸ›  æœ€ä½³å®è·µ
- è®¾è®¡æ¨¡å¼åº”ç”¨
- é”™è¯¯å¤„ç†æœºåˆ¶
- ä»£ç é‡ç”¨æ€§

## ğŸ¯ æ”¹è¿›å»ºè®®
- å…·ä½“ä¿®æ”¹æ–¹æ¡ˆ
- é‡æ„å»ºè®®
- æ€§èƒ½ä¼˜åŒ–æ–¹å‘

**è¯·ä¸ºæ¯ä¸ªé—®é¢˜æä¾›å…·ä½“çš„ä¿®æ”¹å»ºè®®å’Œä»£ç ç¤ºä¾‹ã€‚**`;

    return await this.generateResponse(reviewPrompt, {
      provider: 'openai',
      model: 'gpt-4',
      temperature: 0.3,
      maxTokens: 3000,
    });
  }

  // è°ƒè¯•åŠ©æ‰‹
  async debugError(error: string, code?: string, context?: string): Promise<string> {
    const debugPrompt = `ä½œä¸ºè°ƒè¯•ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹é”™è¯¯ï¼š

**é”™è¯¯ä¿¡æ¯:**
${error}

${code ? `**ç›¸å…³ä»£ç :**
\`\`\`
${code}
\`\`\`` : ''}

${context ? `**ä¸Šä¸‹æ–‡ä¿¡æ¯:**
${context}` : ''}

**è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œåˆ†æ:**

## ğŸ¯ é”™è¯¯å®šä½
- é”™è¯¯ç±»å‹åˆ†ç±»
- å‘ç”Ÿä½ç½®å®šä½
- è§¦å‘æ¡ä»¶åˆ†æ

## ğŸ” æ ¹å› åˆ†æ
- ç›´æ¥åŸå› 
- æ ¹æœ¬åŸå› 
- ç›¸å…³å› ç´ 

## âš¡ è§£å†³æ–¹æ¡ˆ
### ä¸´æ—¶ä¿®å¤æ–¹æ¡ˆ
- å¿«é€Ÿè§£å†³æ–¹æ³•
- é£é™©è¯„ä¼°

### é•¿æœŸè§£å†³æ–¹æ¡ˆ  
- å½»åº•ä¿®å¤æ–¹æ³•
- ä»£ç é‡æ„å»ºè®®

## ğŸ›¡ï¸ é¢„é˜²æªæ–½
- ç±»ä¼¼é—®é¢˜é¢„é˜²
- ä»£ç è´¨é‡æ”¹è¿›
- æµ‹è¯•ç”¨ä¾‹å»ºè®®

**è¯·æä¾›å…·ä½“çš„ä»£ç ä¿®æ”¹ç¤ºä¾‹ã€‚**`;

    return await this.generateResponse(debugPrompt, {
      provider: 'openai',
      model: 'gpt-4',
      temperature: 0.3,
    });
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const aiService = new AIService();